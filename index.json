[{"authors":["bob"],"categories":null,"content":"Bob Slevc is an Associate Professor and Director of Graduate Studies in the Department of Psychology, part of the Neuroscience and Cognitive Science program and of the Maryland Language Science Center.\n","date":1565136000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1565136000,"objectID":"98e3645ed117a1cb24871c324ff07bb9","permalink":"https://lmcl-umd.github.io./authors/bob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/bob/","section":"authors","summary":"Bob Slevc is an Associate Professor and Director of Graduate Studies in the Department of Psychology, part of the Neuroscience and Cognitive Science program and of the Maryland Language Science Center.","tags":null,"title":"L. Robert Slevc","type":"authors"},{"authors":["ogg"],"categories":null,"content":"Mattson Ogg completed his Ph.D. in Neuroscience and Cognitive Science in April, 2019 (dissertation title: The acoustic factors that influence auditory object and event recognition over time). He is currently an audio/speech signal processing engineer at the Johns Hopkins University Applied Physics Laboratory.\n","date":1565136000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1565136000,"objectID":"22fc76e643ba788893b72142baf527ad","permalink":"https://lmcl-umd.github.io./authors/ogg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ogg/","section":"authors","summary":"Mattson Ogg completed his Ph.D. in Neuroscience and Cognitive Science in April, 2019 (dissertation title: The acoustic factors that influence auditory object and event recognition over time). He is currently an audio/speech signal processing engineer at the Johns Hopkins University Applied Physics Laboratory.","tags":null,"title":"Mattson Ogg","type":"authors"},{"authors":["okada"],"categories":null,"content":"Brooke Okada completed her Ph.D. in Psychology in August, 2018 (dissertation title: Toward a comprehensive model of musical ability). She is currently a data analyst at Sisco LABS.\n","date":1565136000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1565136000,"objectID":"e46c410d41030e161f431085f56224b5","permalink":"https://lmcl-umd.github.io./authors/okada/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/okada/","section":"authors","summary":"Brooke Okada completed her Ph.D. in Psychology in August, 2018 (dissertation title: Toward a comprehensive model of musical ability). She is currently a data analyst at Sisco LABS.","tags":null,"title":"Brooke M. Okada","type":"authors"},{"authors":["abubakari"],"categories":null,"content":"Zenab Abubakari is currently a junior at the University of Maryland, College Park. She is pursuing a double major in Psychology and Economics. She hopes to attend graduate school after attending Maryland.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"cc7439c35cff7345ad7b2c346aab763f","permalink":"https://lmcl-umd.github.io./authors/abubakari/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/abubakari/","section":"authors","summary":"Zenab Abubakari is currently a junior at the University of Maryland, College Park. She is pursuing a double major in Psychology and Economics. She hopes to attend graduate school after attending Maryland.","tags":null,"title":"Zenab Abubakari","type":"authors"},{"authors":["admin"],"categories":null,"content":"In the Language and Music Cognition Lab at University of Maryland, we focus on\u0026hellip;\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://lmcl-umd.github.io./authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"In the Language and Music Cognition Lab at University of Maryland, we focus on\u0026hellip;","tags":null,"title":"Language and Music Cognition Lab","type":"authors"},{"authors":["andres"],"categories":null,"content":"Andrés is a President\u0026rsquo;s Postdoctoral Fellow in the Psychology department at the University of Maryland. His research focuses on how people produce and understand speech and prosody. He is especially interested in how speakers and listeners integrate information from different levels of linguistic representation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"9e868dbbe6f9fb7afda2116432b74ef6","permalink":"https://lmcl-umd.github.io./authors/andres/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/andres/","section":"authors","summary":"Andrés is a President\u0026rsquo;s Postdoctoral Fellow in the Psychology department at the University of Maryland. His research focuses on how people produce and understand speech and prosody. He is especially interested in how speakers and listeners integrate information from different levels of linguistic representation.","tags":null,"title":"Andrés Buxó-Lugo","type":"authors"},{"authors":["burns"],"categories":null,"content":"Camille is a current undergrad pursing a major in psychology and a minor in neuroscience. She is fascinated by practically everything, but her main interests include speech/language production, music, and neuropharmacology. In her free time, she is an avid artist and ultimate frisbee player.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"352f584744130e616bcf2ce97708fdd1","permalink":"https://lmcl-umd.github.io./authors/burns/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/burns/","section":"authors","summary":"Camille is a current undergrad pursing a major in psychology and a minor in neuroscience. She is fascinated by practically everything, but her main interests include speech/language production, music, and neuropharmacology. In her free time, she is an avid artist and ultimate frisbee player.","tags":null,"title":"Camille Burns","type":"authors"},{"authors":["cole"],"categories":null,"content":"Alissa is a senior psychology major with minors in neuroscience and hearing and speech sciences. She is currently working on her honors thesis looking at predictive language processing. After graduating, she hopes to attend graduate school to obtain a PhD in clinical psychology.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"d96ec863c1284e8673d719db83b0d97b","permalink":"https://lmcl-umd.github.io./authors/cole/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/cole/","section":"authors","summary":"Alissa is a senior psychology major with minors in neuroscience and hearing and speech sciences. She is currently working on her honors thesis looking at predictive language processing. After graduating, she hopes to attend graduate school to obtain a PhD in clinical psychology.","tags":null,"title":"Alissa Cole","type":"authors"},{"authors":["dadkhoo"],"categories":null,"content":"Hi! My name is Donna Dadkhoo and I am a Junior Psychology major on the Pre-Med track. I am from Potomac, Maryland, and my family is from Iran, so I am bilingual in Farsi and English. Some of my favorite things include trips to DC, going to music festivals, and eating Ledo’s pizza.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"f67531aecfef2d72a96ff4eeec174b30","permalink":"https://lmcl-umd.github.io./authors/dadkhoo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/dadkhoo/","section":"authors","summary":"Hi! My name is Donna Dadkhoo and I am a Junior Psychology major on the Pre-Med track. I am from Potomac, Maryland, and my family is from Iran, so I am bilingual in Farsi and English. Some of my favorite things include trips to DC, going to music festivals, and eating Ledo’s pizza.","tags":null,"title":"Donna Dadkhoo","type":"authors"},{"authors":["kim"],"categories":null,"content":"Yusol is from Ellicott City, Maryland. She is interested in Educational Psychology to enhance student’s education and well-being. She Plans to attend Grad School in the future.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"9ce11e2951f5d7c4d0b618ee41a16f79","permalink":"https://lmcl-umd.github.io./authors/kim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kim/","section":"authors","summary":"Yusol is from Ellicott City, Maryland. She is interested in Educational Psychology to enhance student’s education and well-being. She Plans to attend Grad School in the future.","tags":null,"title":"Yusol Kim","type":"authors"},{"authors":["peabody"],"categories":null,"content":"Lydia is an undergraduate student from Bethesda, Maryland studying Psychology with a minor in General Business. She has a passion for music and is eager to learn any and everything about the way we think about and process music.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"5a6c264caf499d0a0a91f1d261b8696f","permalink":"https://lmcl-umd.github.io./authors/peabody/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/peabody/","section":"authors","summary":"Lydia is an undergraduate student from Bethesda, Maryland studying Psychology with a minor in General Business. She has a passion for music and is eager to learn any and everything about the way we think about and process music.","tags":null,"title":"Lydia Peabody","type":"authors"},{"authors":["salig"],"categories":null,"content":"Lauren is a graduate student in the Neuroscience and Cognitive Science program. She is originally from Downingtown, Pennsylvania. Lauren received a bachelor\u0026rsquo;s degree in psychology and Spanish from Elon University in 2017 and spent a year after graduation in Neuquén, Argentina teaching English on a Fulbright grant. For her graduate studies, she is interested in researching language processing through an intercultural lens that considers how language processing might be affected by bilingualism, accents, code-switching, and the like.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"9a7f43f7a15e851f4041fae79ee048a6","permalink":"https://lmcl-umd.github.io./authors/salig/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/salig/","section":"authors","summary":"Lauren is a graduate student in the Neuroscience and Cognitive Science program. She is originally from Downingtown, Pennsylvania. Lauren received a bachelor\u0026rsquo;s degree in psychology and Spanish from Elon University in 2017 and spent a year after graduation in Neuquén, Argentina teaching English on a Fulbright grant. For her graduate studies, she is interested in researching language processing through an intercultural lens that considers how language processing might be affected by bilingualism, accents, code-switching, and the like.","tags":null,"title":"Lauren Salig","type":"authors"},{"authors":["santomartino"],"categories":null,"content":"Sam Santomartino is a recent graduate of Bucknell University where she earned her Bachelor or Arts in Computer Science and Economics. Interested in musical cognition and neurology, Sam is doing research to gain more exposure to the fields while she takes some additional classes at the University of Maryland.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2a48e7a9cedb9f03200dcfd2d199fb3e","permalink":"https://lmcl-umd.github.io./authors/santomartino/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/santomartino/","section":"authors","summary":"Sam Santomartino is a recent graduate of Bucknell University where she earned her Bachelor or Arts in Computer Science and Economics. Interested in musical cognition and neurology, Sam is doing research to gain more exposure to the fields while she takes some additional classes at the University of Maryland.","tags":null,"title":"Samantha Santomartino","type":"authors"},{"authors":["shell"],"categories":null,"content":"Alison Shell completed her Ph.D. in Psychology in October, 2018 (dissertation title: The what And where of control in bilingual language switching). She is currently a research fellow at Digital Promise.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"543876cb75275c0224876064ecf4be79","permalink":"https://lmcl-umd.github.io./authors/shell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/shell/","section":"authors","summary":"Alison Shell completed her Ph.D. in Psychology in October, 2018 (dissertation title: The what And where of control in bilingual language switching). She is currently a research fellow at Digital Promise.","tags":null,"title":"Alison Shell","type":"authors"},{"authors":["thompson"],"categories":null,"content":"Rachel is a doctoral student in the Neuroscience and Cognitive Science (NACS) program at the University of Maryland College Park. She received her bachelor’s degree in psychology and music from St. Mary’s College of Maryland in 2019. She is interested in music perception and production, music memory, and the relationship between music and language.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"f977c31d50911f543536028fbb4b7e00","permalink":"https://lmcl-umd.github.io./authors/thompson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/thompson/","section":"authors","summary":"Rachel is a doctoral student in the Neuroscience and Cognitive Science (NACS) program at the University of Maryland College Park. She received her bachelor’s degree in psychology and music from St. Mary’s College of Maryland in 2019. She is interested in music perception and production, music memory, and the relationship between music and language.","tags":null,"title":"Rachel Thompson","type":"authors"},{"authors":null,"categories":null,"content":"","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"60c5565aef0f445733303876c1c37ba5","permalink":"https://lmcl-umd.github.io./doc/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/doc/example/","section":"doc","summary":"All you need to know about LMCL, software documentation, and tutorials.","tags":null,"title":"Lab Manual","type":"docs"},{"authors":null,"categories":null,"content":"The LMCL now maintains a blog, hosted by Medium. If you\u0026rsquo;re enrolled in PSYC 479, one option for your \u0026lsquo;final paper\u0026rsquo; is to contribute a blog post about some topic related to language and/or music cognition that you find interesting.\nThe blog can be found at our lab publication section on Medium.\nIdeally, these posts should:\n describe the findings of a recent primary source article about music perception/cognition (ideally referring to additional relevant sources as well). target an intelligent, but non-expert, audience. Consider the advice here, for example.  You could find recent interesting and relevant work in lots of ways. If you have a topic in mind, try google scholar (I suggest you constrain your search to the last year or two). If you have an older paper you\u0026rsquo;re interested in, try a cited reference search (click \u0026ldquo;Cited by\u0026hellip;\u0026rdquo; under the google scholar result for that paper) to see if there\u0026rsquo;s some newer relevant research that you could include. And if you don\u0026rsquo;t yet have a topic in mind, try browsing recent tables of contents from some journals that publish relevant research \u0026ndash; here are some suggestions (though definitely not an exhaustive list - and note that you may need on-campus or proxy access to get some of these journals):\n Brain \u0026amp; Language Cognition Journal of Cognitive Neuroscience JEP:LMC or JEP:HPP (note that you\u0026rsquo;ll annoyingly have to dig around PsycINFO to get access to these articles) Language, Cognition and Neuroscience Neuropsychologia Psychological Science Psychology of Music Psychonomic Bulletin \u0026amp; Review  Here\u0026rsquo;s some basic info on writing a post in Medium, adding your post to the lab publication, and on embedding content in your post. (note: please un-check \u0026ldquo;Allow curators to recommend my story\u0026rdquo; when you publish.)\nFinally, here are a few examples of (IMHO) good science writing. You should, of course, find your own voice, but these are some good examples of the type of writing we\u0026rsquo;re hoping for:\n PsychoBabble Psychonomic Society blog Vicky Williamson\u0026rsquo;s Music Psychology blog and many more (please send me suggestions if you have \u0026lsquo;em!)  Happy writing!\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"38d381d9d2361b86d6dfa5524182dbd2","permalink":"https://lmcl-umd.github.io./doc/example/bloginfo/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/doc/example/bloginfo/","section":"doc","summary":"The LMCL now maintains a blog, hosted by Medium. If you\u0026rsquo;re enrolled in PSYC 479, one option for your \u0026lsquo;final paper\u0026rsquo; is to contribute a blog post about some topic related to language and/or music cognition that you find interesting.\nThe blog can be found at our lab publication section on Medium.\nIdeally, these posts should:\n describe the findings of a recent primary source article about music perception/cognition (ideally referring to additional relevant sources as well).","tags":null,"title":"The LMCL Blog","type":"docs"},{"authors":null,"categories":null,"content":" Overview: Our lab uses and maintains three Google Calendars to books and schedule the three rooms in BPS 3150.\nThose three calendars are:\nLMCL 3150A LMCL 3150B LMCL 3150G\nTo gain access to the calendars, ask Dr, Slevc to share them with your given gmail account. Once you have access, you can reserve the desired room by simply adding an event with your name as the subject from the time you need in the desired room\u0026rsquo;s calendar.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"6cc38b4f3cf25885d3ed841a1be01dcb","permalink":"https://lmcl-umd.github.io./doc/example/calendars/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/doc/example/calendars/","section":"doc","summary":"Overview: Our lab uses and maintains three Google Calendars to books and schedule the three rooms in BPS 3150.\nThose three calendars are:\nLMCL 3150A LMCL 3150B LMCL 3150G\nTo gain access to the calendars, ask Dr, Slevc to share them with your given gmail account. Once you have access, you can reserve the desired room by simply adding an event with your name as the subject from the time you need in the desired room\u0026rsquo;s calendar.","tags":null,"title":"Google Calendars","type":"docs"},{"authors":null,"categories":null,"content":" Information about the iMac computers in the lab If you want to update the software on the iMac Computers, you have to first check the compatibility with the version number.\nYou can go to The Apple icon in the top left corner \u0026gt; About This Mac\nThe model number will tell you when the iMac was released and the version number will tell you what version of OS your computer is running.\nIf the computer is running software 10.7 or below, you will have to go online and download and install the next version of software yourself (rather than through the App Store).\nTo download El Capitan follow the instructions here.\nTo download High Sierra follow the instructions here.\n Note: if the iMac is version 11,2 (i.e. mid 2010) or earlier, the highest OS you can upgrade to is High Sierra \n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"a786ff5166936262966094772277ad2d","permalink":"https://lmcl-umd.github.io./doc/example/imacsoftware/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/doc/example/imacsoftware/","section":"doc","summary":"Information about the iMac computers in the lab If you want to update the software on the iMac Computers, you have to first check the compatibility with the version number.\nYou can go to The Apple icon in the top left corner \u0026gt; About This Mac\nThe model number will tell you when the iMac was released and the version number will tell you what version of OS your computer is running.","tags":null,"title":"LMCL iMac Computers","type":"docs"},{"authors":null,"categories":null,"content":" How to update to Psychopy3 on your computer As of 11/1/2019, the standalone package to download Psychopy3 from the Psychopy website does not contain the correct dependencies required for using some of the features we need in the LMCL (such as the pyo library for audio and voice keys).\nThe work around is to download the source code via the terminal and adjust the dependencies yourself. Instructions for this are outlined on the Psychopy website but require additional manipulation to work in the capacity required for this lab. Additional instructions have been outlined below.\nFor Mac users:  OS must be updated to version 10.12 or higher must be running python 3.6 or higher use pip3 to install pyo use pip3 to install pyglet == 1.2.4  After the above is complete can you can:\npip3 install psychopy\nTo now open and run psychopy3, open the command line terminal and simply type \u0026ldquo;psychopy\u0026rdquo;\nFor PC users: Follow the instructions on the Psychopy website.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"486c52b685f465ac989ab716ba6cd9af","permalink":"https://lmcl-umd.github.io./doc/example/psychopyupdate/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/doc/example/psychopyupdate/","section":"doc","summary":"How to update to Psychopy3 on your computer As of 11/1/2019, the standalone package to download Psychopy3 from the Psychopy website does not contain the correct dependencies required for using some of the features we need in the LMCL (such as the pyo library for audio and voice keys).\nThe work around is to download the source code via the terminal and adjust the dependencies yourself. Instructions for this are outlined on the Psychopy website but require additional manipulation to work in the capacity required for this lab.","tags":null,"title":"Psychopy Tips and Tricks","type":"docs"},{"authors":null,"categories":null,"content":" System Design: The LMCL website is built using a Hugo website framework and hosted on Github Pages. We implemented the Hugo Academic theme. The Academic theme uses a series of templates called \u0026ldquo;widgets\u0026rdquo; that can copied and edited as needed to build the site.\nOur website is available at: http://lmcl-umd.github.io.\nSystem Requirements: In order to edit and update the website, you must have the following installed on your machine:\nHomebrew\nHugo\nGit\nGithub Repositories: The code for our website is hosted on Github. The username for our lab\u0026rsquo;s GitHub is lmcl-umd. Contact Dr. Slevc for the password if/when needed for SSH authentication (see \u0026ldquo;Editing the Website\u0026rdquo; below). There are two repositories in which the code lives:  websiteWork  lmcl-umd.github.io.\nThe websiteWork repository is where the working code lives while the lmcl-umd.github.io. repository is where the live code lives.\n Note: You will only ever have to change code in websiteWork and that will automatically update the live code in the lmcl-umd.github.io. repository. \nEditing/Updating the Website: In order to edit the website, you must clone the websiteWork repository from git onto your local machine. When you clone the websiteWork repository, the \u0026ldquo;public\u0026rdquo; folder from the code will also be copied onto your machine. This folder, in layman\u0026rsquo;s terms, manages the updates to the site repository. In order to set this automatic updating up, you must run the following code snippets:\n#completely remove the current public directory rm -rf public #creates a git submodule: builds your site to public where the created public directory will have a different remote origin (i.e. hosted GitHub repository) git submodule add -b master git@github.com:lmcl-umd/lmcl-umd.github.io.git public #runs the first build of public hugo  After the website files are locally on your machine and your public directory is set up, you can make changes that will be visible both locally and on the master site. Before you push them back up to the websiteWork repository, run the following code snippet:\n./deploy.sh \u0026quot;Your commit message\u0026quot;  This deploy command will push your edits to the lmcl-umd.github.io. repository and after a couple of minutes, your changes will appear on the live website.\nIn order to clone and push edits via git, you must first have git set up on your computer and authenticate our lmcl-umd GitHub account via your computer\u0026rsquo;s unique SSH key.\nHelpful Git Commands: # clone the repository git clone https://github.com/lmcl-umd/websiteWork.git # deploy edits to lmcl-umd.github.io. repository # your commit message should describe the edits made ./deploy.sh \u0026quot;your commit message\u0026quot; # add edits to websiteWork repository git add * # commit edits to websiteWork repository # your commit message should describe the edits made git commit -m \u0026quot;your commit message\u0026quot; # push edits to websiteWork repository git push  Multiple Git Users: If there are multiple users updating the website from multiple devices, the websiteWork repository on your local machine may be out of date from time to time. To ensure that you always have the most up to date version of the website code, you must \u0026ldquo;pull\u0026rdquo; it down from the repository before you make any changes yourself.\ngit pull  Read the output of this code carefully. If the word \u0026ldquo;error\u0026rdquo; or \u0026ldquo;aborting\u0026rdquo; is present after you try to pull the websiteWork repository, something went wrong. The most likely problem is that there are some untracked files between the two versions of code (the version in the repository and the version on your local machine) and git is unable to merge them. To resolve this issue, run the following two code snippets:\ngit fetch --all git reset --hard origin/master  Now, you should be able to run the pull command again and successfully get an updated version of the code.\ngit pull  At this point, you can make your own changes to any of the websiteWork files and deploy, git add, git commit, and git push as you normally would.\nCode Organization: After you clone the websiteWork repository, you will see a folder called \u0026ldquo;websiteWork\u0026rdquo; on your computer. Within that folder are many, many subdirectories. The main folders most relevant for editing, however, are:\ncontent: holds all the actual editable content on the site; subdirectories within this folder are named to indicate which sections of the site they house information on config: holds the more administrative, website configuration files static: holds images and other files such as publication odds or profile cv\u0026rsquo;s for reference by other folders layouts: the main back-end of the website that holds all style sheets, and design of the site\n Do NOT ever edit the public folder in this repository It handles the automatic deployment to the main website and should not be edited.\nFor more information on managing and writing content see the Hugo Academic source documentation.\nMake Edits without Deploying What if you want to just play around and see how something will look before actually deploying to the website?\nWe also have a version of the website\u0026rsquo;s code (and example code) on DropBox. This code is not live and can be run locally. Enter the lmclSite folder via the terminal and then type the command\nhugo server  Next open a web-browser and type\nlocalhost:1313  The code will render in the browser.\nFor access to the DropBox code, contact Dr. Slevc and you will be granted access for editing.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"4697ae2b05fda60a81d09974b5ce4e00","permalink":"https://lmcl-umd.github.io./doc/example/editwebsite/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/doc/example/editwebsite/","section":"doc","summary":"System Design: The LMCL website is built using a Hugo website framework and hosted on Github Pages. We implemented the Hugo Academic theme. The Academic theme uses a series of templates called \u0026ldquo;widgets\u0026rdquo; that can copied and edited as needed to build the site.\nOur website is available at: http://lmcl-umd.github.io.\nSystem Requirements: In order to edit and update the website, you must have the following installed on your machine:","tags":null,"title":"LMCL Website Overview","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://lmcl-umd.github.io./talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Mattson Ogg","Thomas Carlson","L. Robert Slevc"],"categories":null,"content":"","date":1565136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565136000,"objectID":"d66f523b28ff41f12cc032fecd046c53","permalink":"https://lmcl-umd.github.io./publication/pub1/","publishdate":"2019-08-07T00:00:00Z","relpermalink":"/publication/pub1/","section":"publication","summary":"Human listeners are bombarded by acoustic information that the brain rapidly organizes into coherent percepts of objects and events in the environment, which aids speech and music perception. The efficiency of auditory object recognition belies the critical constraint that acoustic stimuli necessarily require time to unfold. Using magentoencephalography (MEG), we studied the time course of the neural processes that transform dynamic acoustic information into auditory object representations. Participants listened to a diverse set of 36 tokens comprising everyday sounds from a typical human environment. Multivariate pattern analysis was used to decode the sound tokens from the MEG recordings. We show that sound tokens can be decoded from brain activity beginning 90 milliseconds after stimulus onset with peak decoding performance occurring at 155 milliseconds post stimulus onset. Decoding performance was primarily driven by differences between category representations (e.g., environmental vs. instrument sounds), although within-category decoding was better than chance. Representational similarity analysis revealed that these emerging neural representations were related to harmonic and spectrotemporal differences among the stimuli, which correspond to canonical acoustic features processed by the auditory pathway. Our findings begin to link the processing of physical sound properties with the perception of auditory objects and events in cortex.","tags":["Auditory","Magnetoencephalography","Multivariate Pattern Analysis","Object Perception","Representational Similarity Analysis"],"title":"The rapid emergence of auditory object representations in cortex reflect central acoustic attributes","type":"publication"},{"authors":["Mattson Ogg","Brooke M. Okada","Jared M. Novick","L. Robert Slevc"],"categories":null,"content":"","date":1565136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565136000,"objectID":"d86a2814b9185f22f118af7c10b6da0b","permalink":"https://lmcl-umd.github.io./publication/pub2/","publishdate":"2019-08-07T00:00:00Z","relpermalink":"/publication/pub2/","section":"publication","summary":"Introduction: The comprehension of musical tonal structure may rely on executive functions, such as cognitive control and working memory updating, to orient the listener to a tonal context and guide the interpretation of incoming information in real time. One specific proposal suggests cognitive control plays a key role when a listener confronts unexpected or irregular musical information. Methods: In two experiments, we simultaneously manipulated musical tonal contexts and non-musical cognitive control engagement. Experiment 1 used a 2-back tone-matching task with lures (engaging both cognitive control and working memory) and Experiment 2 used a Stroop task performed in a harmonic priming paradigm. Results: In Experiment 1, participants had difficulty overcoming conflict from lure trials, especially when tone frequencies occupied an irregular tonal context. However, in Experiment 2, the harmonic priming manipulation did not affect Stroop-conflict performance. Discussion: We interpret these results in terms of conflict monitoring and conflict resolution. Incorporating unexpected or ambiguous musical information appears to rely on cognitive control, however, cognitive control engagement depends on the specific task characteristics and demands. Nevertheless, these findings help explain a critical aspect of music cognition in terms of higher-order cognitive processes.","tags":["Cognitive Control","working memory updating","music","n-back","Stroop"],"title":"Updating musical tonal structure in working memory engages cognitive control","type":"publication"},{"authors":["Mattson Ogg","L. Robert Slevc"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"ea96679f290aa8a2a1aacb90136a098c","permalink":"https://lmcl-umd.github.io./publication/pub3/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/pub3/","section":"publication","summary":"Human listeners must identify and orient themselves to auditory objects and events in their environment. What acoustic features support a listener’s ability to differentiate the great variety of natural sounds they might encounter? Studies of auditory object perception typically examine identification (and confusion) responses or dissimilarity ratings between pairs of objects and events. However, the majority of this prior work has been conducted within single categories of sound. This separation has precluded a broader understanding of the general acoustic attributes that govern auditory object and event perception within and across different behaviorally relevant sound classes. The present experiments take a broader approach by examining multiple categories of sound relative to one another. This approach bridges critical gaps in the literature and allows us to identify (and assess the relative importance of) features that are useful for distinguishing sounds within, between and across behaviorally relevant sound categories. To do this, we conducted behavioral sound identification (Experiment 1) and dissimilarity rating (Experiment 2) studies using a broad set of stimuli that leveraged the acoustic variability within and between different sound categories via a diverse set of 36 sound tokens (12 utterances from different speakers, 12 instrument timbres, and 12 everyday objects from a typical human environment). Multidimensional scaling solutions as well as analyses of item-pair-level responses as a function of different acoustic qualities were used to understand what acoustic features informed participants’ responses. In addition to the spectral and temporal envelope qualities noted in previous work, listeners’ dissimilarity ratings were associated with spectrotemporal variability and aperiodicity. Subsets of these features (along with fundamental frequency variability) were also useful for making specific within or between sound category judgments. Dissimilarity ratings largely paralleled sound identification performance, however the results of these tasks did not completely mirror one another. In addition, musical training was related to improved sound identification performance.","tags":["auditory object","acoustics","timbre","speaker identification","environmental sound"],"title":"Acoustic correlates of auditory object and event perception: Speakers, musical timbres and environmental sounds","type":"publication"},{"authors":["Yasmeen Faroqi-Shah","L. Robert Slevc","Sadhvi Saxena","Sarah J. Fisher","Madeline Pifer"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"0000ad632321f4d844a1640a2ff17dad","permalink":"https://lmcl-umd.github.io./publication/pub44/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/pub44/","section":"publication","summary":"The relationship between structural processing in music and language can be viewed from two perspectives: whether the neural processing of music and language recruits shared neural resources, and whether musical ability is associated with neuroplastic resilience against language impairment","tags":["Aphasia","cognitive reserve","language","music","syntax"],"title":"Relationship between musical and language abilities in post-stroke aphasia","type":"publication"},{"authors":["Mattson Ogg","Dustin Moraczewski","Stefanie E. Kuchinsky","L. Robert Slevc"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"3d4fe2cbeb71feb5583d73c15c9916f4","permalink":"https://lmcl-umd.github.io./publication/pub5/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/pub5/","section":"publication","summary":"Human listeners can quickly and easily recognize different sound sources (objects and events) in their environment. Understanding how this impressive ability is accomplished can improve signal processing and machine intelligence applications along with assistive listening technologies. However, it is not clear how the brain represents the many sounds that humans can recognize (such as speech and music) at the level of individual sources, categories and acoustic features. To examine the cortical organization of these representations, we used patterns of fMRI responses to decode 1) four individual speakers and instruments from one another (separately, within each category), 2) the superordinate category labels associated with each stimulus (speech or instrument), and 3) a set of simple synthesized sounds that could be differentiated entirely on their acoustic features. Data were collected using an interleaved silent steady state sequence to increase the temporal signal-to-noise ratio, and mitigate issues with auditory stimulus presentation in fMRI. Largely separable clusters of voxels in the temporal lobes supported the decoding of individual speakers and instruments from other stimuli in the same category. Decoding the superordinate category of each sound was more accurate and involved a larger portion of the temporal lobes. However, these clusters all overlapped with areas that could decode simple, acoustically separable stimuli. Thus, individual sound sources from different sound categories are represented in separate regions of the temporal lobes that are situated within regions implicated in more general acoustic processes. These results bridge an important gap in our understanding of cortical representations of sounds and their acoustics.","tags":["fMRI","auditory object","auditory perception","speaker identification","speech","timbre"],"title":"Separable neural representations of sound sources: Speaker identity and musical timbres","type":"publication"},{"authors":["Mattson Ogg","L. Robert Slevc"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"b4f595508b22e9c584fda73fd5cfbf32","permalink":"https://lmcl-umd.github.io./publication/pub6/","publishdate":"2019-04-01T00:00:00Z","relpermalink":"/publication/pub6/","section":"publication","summary":"","tags":["fMRI","auditory object","auditory perception","speaker identification","speech","timbre"],"title":"Neural mechanisms of music and language","type":"publication"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://lmcl-umd.github.io./slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"84ac0461d7e0763016a461d9e8fdea15","permalink":"https://lmcl-umd.github.io./involve/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/involve/","section":"","summary":"","tags":null,"title":"Get Involved","type":"widget_page"},{"authors":["Michael R. Dougherty","L. Robert Slevc","James A. Grand"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"e4626ed739a483975359b0ca1fee7d10","permalink":"https://lmcl-umd.github.io./publication/pub4/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/pub4/","section":"publication","summary":"There is a growing interest in changing the culture of psychology to improve the quality of our science. At the root of this interest is concern over the reproducibility of key findings. A variety of large-scale replication attempts have revealed that a number of previously published effects cannot be reproduced, while other analyses indicate that the published literature is rife with underpowered studies and publication bias. These revelations suggest that it is time to change how psychological science is carried out and increase transparency of reporting. We argue change will be slow until institutions adopt new procedures for evaluating scholarly activity. We consider three actions that individuals and departments can take to facilitate change throughout psychological science. These three actions are the development of individualized research philosophy statements, the creation of an annotated curriculum vitae to improve the transparency of scholarly reporting, and the use of a formal evaluative system that explicitly captures behaviors that support reproducibility. Our recommendations build on proposals for open science by enabling researchers to have a voice in articulating (and contextualizing) how they would like their work to be evaluated and by providing a mechanism for more detailed and transparent reporting of scholarly activities.","tags":["open science","reproducibility","research philosophy","annotated curriculum vitae"],"title":"Making research evaluation more transparent: Aligning research philosophy, institutional values, and reporting","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"23d1e75f872528fc12f5f2b142375ff7","permalink":"https://lmcl-umd.github.io./publications/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publications/","section":"","summary":"","tags":null,"title":"Publications","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c6625328e7b2e36b114847f299065f54","permalink":"https://lmcl-umd.github.io./resources/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/resources/","section":"","summary":"","tags":null,"title":"Resources","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://lmcl-umd.github.io./people/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"Who are we","type":"widget_page"},{"authors":["Hao Yan","Randi C. Martin","L. Robert Slevc"],"categories":null,"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541030400,"objectID":"6d567b06666bde23bde7f457abd11ab5","permalink":"https://lmcl-umd.github.io./publication/pub8/","publishdate":"2018-11-01T00:00:00Z","relpermalink":"/publication/pub8/","section":"publication","summary":"Speakers show syntactic priming – that is, a tendency to repeat syntactic constructions they have recently comprehended or produced – and this tendency is even stronger when adjacent utterances share the same main verb, termed the lexical boost. Some have suggested that abstract syntactic priming (i.e., with no lexical overlap) derives from implicit learning, whereas the lexical boost derives from explicit short-term memory (STM) for the prime (e.g., Chang, Dell, \u0026 Bock, 2006). To address this issue, we assessed twelve people with aphasia (PWA) with varying degrees of STM and language deficits and eleven age-matched healthy control speakers in a syntactic priming experiment. Despite the PWA's difficulty in maintaining phonological, semantic, and structural information, as evidenced by various STM and sentence repetition measures, they showed lexical boost effects comparable to those of healthy speakers. Moreover, the size of the lexical boost was unrelated to the degree of STM deficit, suggesting that the lexical boost does not rely on explicit memory. Alternative explanations for the differing patterns for syntactic priming with and without lexical overlap are discussed.","tags":["Syntactic priming","Lexical boost","sentence production","short-term memory","implicit learning","aphasia"],"title":"Lexical overlap increases syntactic priming in aphasia independently of short-term memory abilities: Evidence against the explicit memory account of the lexical boost","type":"publication"},{"authors":["Victor S. Ferreira","Adam Morgan","L. Robert Slevc"],"categories":null,"content":"","date":1533081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533081600,"objectID":"b33bfe5d8ea80187275ac336d072acf7","permalink":"https://lmcl-umd.github.io./publication/pub10/","publishdate":"2018-08-01T00:00:00Z","relpermalink":"/publication/pub10/","section":"publication","summary":"Grammatical encoding has the task of selecting and retrieving the syntactic and lexical forms that can convey non-linguistic thoughts, and then determining the morphological forms and their constituent ordering in preparation for their phonological spell-out and eventual externalization. This chapter begins by broadly describing a consensus view of the general architecture of grammatical encoding. It then describes ongoing debates that operate within (or question aspects of) this consensus view, including about the content and structure and selection-then-retrieval character of grammatical encoding; the incrementality or scope of grammatical encoding; the factors that influence syntactic choice; the rational or optimal nature of production; effects of ongoing learning; and production in dialogue. It closes on a constructive note, highlighting fundamental insights that we have gained as a field along the way.","tags":["sentence production","grammatical encoding","syntactic formulation","syntactic choice","lexical retrieval"],"title":"Grammatical encoding","type":"publication"},{"authors":["Brooke M. Okada","L. Robert Slevc"],"categories":null,"content":"","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"d813ece211552140caaead9967c45c6b","permalink":"https://lmcl-umd.github.io./publication/pub7/","publishdate":"2018-05-01T00:00:00Z","relpermalink":"/publication/pub7/","section":"publication","summary":"Learning and performing music draw on a host of cognitive abilities, and previous research has postulated that musicians might have advantages in related cognitive processes. One such aspect of cognition that may be related to musical training is executive functions (EFs), a set of top-down processes that regulate behavior and cognition according to task demands. Previous studies investigating the link between musical training and EFs have yielded mixed results and are difficult to compare. In part, this is because most studies have looked at only one specific cognitive process, and even studies looking at the same process have used different experimental tasks. Furthermore, most correlational studies have used different “musician” and “non-musician” categorizations for their comparisons, so generalizing the findings is difficult. The present study provides a more comprehensive assessment of how individual differences in musical training relate to latent measures of three separable aspects of EFs. We administered a well-validated EF battery containing multiple tasks tapping the EF components of inhibition, shifting, and working memory updating (Friedman et al. in Journal of Experimental Psychology: General, 137, 201–225, 2008), as well as a comprehensive, continuous measure of musical training and sophistication (Müllensiefen et al., in PLoS ONE, 9, e89642, 2014). Musical training correlated with some individual EF tasks involving inhibition and working memory updating, but not with individual tasks involving shifting. However, musical training only predicted the latent variable of working memory updating, but not the latent variables of inhibition or shifting after controlling for IQ, socioeconomic status, and handedness. Although these data are correlational, they nonetheless suggest that musical experience places particularly strong demands specifically on working memory updating processes.","tags":["musical training","executive functions","latent variable analysis"],"title":"Individual differences in musical training and Executive Functions: A latent variable approach","type":"publication"},{"authors":["Shota Momma","L. Robert Slevc","Colin Phillips"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"a18bdd75b86a12c0b2959fdd96488ede","permalink":"https://lmcl-umd.github.io./publication/pub9/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/pub9/","section":"publication","summary":"Linguistic analyses suggest that there are two types of intransitive verbs: unaccusatives, whose sole argument is a patient or theme (e.g., fall), and unergatives, whose sole argument is an agent (e.g., jump).1 Past psycholinguistic experiments suggest that this distinction affects how sentences are processed: for example, it modulates both comprehension processes (Bever and Sanz 1997, Friedmann et al. 2008) and production processes (Kegl 1995, Kim 2006, M. Lee and Thompson 2004, J. Lee and Thompson 2011, McAllister et al. 2009). Given this body of evidence, it is reasonable to assume, as we do here, that this distinction is directly relevant to psycholinguistic theorizing. However, especially in production, exactly how this distinction affects processing is unknown, beyond the suggestion that unaccusatives somehow involve more complex processing than unergatives (see J. Lee and Thompson 2011). Here we examine how real-time planning processes in production differ for unaccusatives and unergatives. We build on previous studies on lookahead effects in sentence planning that show that verbs are planned before a deep object is uttered but not before a deep subject is uttered (Momma, Slevc, and Phillips 2015, 2016). (We use terms like deep subject in a theory-neutral fashion, with no intended commitment to a specific syntactic encoding.) This line of research sheds light on the broader issue of how the theory of argument structure relates to sentence production.","tags":null,"title":"Unaccusativity in sentence production","type":"publication"},{"authors":["Mattson Ogg","L. Robert Slevc","William J. Idsardi"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"fb0fb31707556bea6a4858ba144c9333","permalink":"https://lmcl-umd.github.io./publication/pub11/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/publication/pub11/","section":"publication","summary":"Humans have an impressive, automatic capacity for identifying and organizing sounds in their environment. However, little is known about the timescales that sound identification functions on, or the acoustic features that listeners use to identify auditory objects. To better understand the temporal and acoustic dynamics of sound category identification, two go/no-go perceptual gating studies were conducted. Participants heard speech, musical instrument, and human-environmental sounds ranging from 12.5 to 200 ms in duration. Listeners could reliably identify sound categories with just 25 ms of duration. In experiment 1, participants' performance on instrument sounds showed a distinct processing advantage at shorter durations. Experiment 2 revealed that this advantage was largely dependent on regularities in instrument onset characteristics relative to the spectrotemporal complexity of environmental sounds and speech. Models of participant responses indicated that listeners used spectral, temporal, noise, and pitch cues in the task. Aspects of spectral centroid were associated with responses for all categories, while noisiness and spectral flatness were associated with environmental and instrument responses, respectively. Responses for speech and environmental sounds were also associated with spectral features that varied over time. Experiment 2 indicated that variability in fundamental frequency was useful in identifying steady state speech and instrument stimuli","tags":null,"title":"The time course of sound category identification: Insights from acoustic features","type":"publication"},{"authors":["Brooke M. Okada","L. Robert Slevc"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"e2ab7535cf5d8d52f0bc44598e777885","permalink":"https://lmcl-umd.github.io./publication/pub13/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/publication/pub13/","section":"publication","summary":"This is a preprint of a chapter on musical training and executive function to appear in \"An Integrative Approach to Cognitive and Working Memory Training: Perspectives from Psychology, Neuroscience, and Human Development\" edited by M. Bunting, J. Novick, M. Dougherty, and R. W. Engle.","tags":["executive function","musical training"],"title":"Musical training: Contributions to Executive Function","type":"publication"},{"authors":["L. Robert Slevc","Iva Ivanova"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"8f097bce26a932f8aab5c005cecb8749","permalink":"https://lmcl-umd.github.io./publication/pub12/","publishdate":"2017-11-01T00:00:00Z","relpermalink":"/publication/pub12/","section":"publication","summary":"Understanding the nature of linguistic representations undoubtedly will benefit from multiple types of evidence, including structural priming. Here, we argue that successfully gaining linguistic insights from structural priming requires us to better understand (1) the precise mappings between linguistic input and comprehenders' syntactic knowledge; and (2) the role of cognitive faculties such as memory and attention in structural priming.","tags":null,"title":"The relationship between priming and linguistic representations is mediated by processing constraints","type":"publication"},{"authors":["L. Robert Slevc","Randi C. Martin"],"categories":null,"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"67fd68b27f6a73fedc42a65b621cc665","permalink":"https://lmcl-umd.github.io./publication/pub16/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/publication/pub16/","section":"publication","summary":"Does producing syntactic agreement rely on syntactic or memory-based retrieval processes? The present study investigated the extent to which syntactic processing deficits and working memory (WM) deficits predict susceptibility to agreement attraction [Bock, K., \u0026 Miller, C. A. (1991). Broken agreement. Cognitive Psychology, 23, 45–93], where speakers tend to erroneously produce plural agreement for a singular subject when another noun in the sentence is grammatically plural. Four brain-injured patients with varying degrees of grammatical and WM deficits completed sentences with local nouns that matched or mismatched in number with the head noun, and that were plausible or implausible subjects. Both aspects of grammatical deficits and the extent of WM deficits predicted the extent of agreement attraction effects. These data are consistent with the proposal that producing an agreeing verb involves a cue-based search in WM for an appropriate controlling noun, which is subject to interference from other elements in memory with similar properties [cf. Badecker, W., \u0026 Kuminiak, F. (2007). Morphology, agreement and working memory retrieval in sentence production: Evidence from gender and case in Slovak. Journal of Memory and Language, 56(1), 65–85. doi:10.1016/j.jml.2006.08.004].","tags":["Syntactic agreement","language production","short-term memory","aphasia"],"title":"Syntactic agreement attraction reflects short-term memory processes","type":"publication"},{"authors":["L. Robert Slevc","Nicholas S. Davey","Martin Buschkuehl","Susanne M. Jaeggi"],"categories":null,"content":"","date":1467331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467331200,"objectID":"a2093fe2f6ff2bfaa7bb24183b1f651d","permalink":"https://lmcl-umd.github.io./publication/pub18/","publishdate":"2016-07-01T00:00:00Z","relpermalink":"/publication/pub18/","section":"publication","summary":"A growing body of research suggests that musical experience and ability are related to a variety of cognitive abilities, including executive functioning (EF). However, it is not yet clear if these relationships are limited to specific components of EF, limited to auditory tasks, or reflect very general cognitive advantages. This study investigated the existence and generality of the relationship between musical ability and EFs by evaluating the musical experience and ability of a large group of participants and investigating whether this predicts individual differences on three different components of EF – inhibition, updating, and switching – in both auditory and visual modalities. Musical ability predicted better performance on both auditory and visual updating tasks, even when controlling for a variety of potential confounds (age, handedness, bilingualism, and socio-economic status). However, musical ability was not clearly related to inhibitory control and was unrelated to switching performance. These data thus show that cognitive advantages associated with musical ability are not limited to auditory processes, but are limited to specific aspects of EF. This supports a process-specific (but modality-general) relationship between musical ability and non-musical aspects of cognition.","tags":["Executive functions","Working memory","Musical ability","Individual differences"],"title":"Tuning the mind: Exploring the connections between musical ability and Executive Functions","type":"publication"},{"authors":null,"categories":null,"content":" Abiola Adesina Tiffany Bamdad * Brittni Bittner Mary Dumler  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"f03d210781efc41a7135f2f6598daaa0","permalink":"https://lmcl-umd.github.io./project/15_16_alum/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/15_16_alum/","section":"project","summary":" Abiola Adesina Tiffany Bamdad * Brittni Bittner Mary Dumler  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Arcadia Ewell Toria Hawkins Kelly Hiden Hope Opia  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"2e6e3c54581713e44f67d81551386c5a","permalink":"https://lmcl-umd.github.io./project/15_16_alum2/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/15_16_alum2/","section":"project","summary":" Arcadia Ewell Toria Hawkins Kelly Hiden Hope Opia  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" McLaine Rich Judith Tsoi  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"6e0c8231892d8242d821add1b6d07e49","permalink":"https://lmcl-umd.github.io./project/15_16_alum3/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/15_16_alum3/","section":"project","summary":" McLaine Rich Judith Tsoi  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Arman Ali William Bartz Brittni Bittner Alexandra Hickey  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8dfa1ef1db6776377bdf6824316202e1","permalink":"https://lmcl-umd.github.io./project/16_17_alum/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/16_17_alum/","section":"project","summary":" Arman Ali William Bartz Brittni Bittner Alexandra Hickey  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Christy Jones Christy Nguyen Jackie Patton Keana Richards  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"88383df2c762914e4943b77de707a784","permalink":"https://lmcl-umd.github.io./project/16_17_alum2/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/16_17_alum2/","section":"project","summary":" Christy Jones Christy Nguyen Jackie Patton Keana Richards  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Jessica Ward Jocelyn Yao  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"5611afd13accdf24772c726a66668183","permalink":"https://lmcl-umd.github.io./project/16_17_alum3/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/16_17_alum3/","section":"project","summary":" Jessica Ward Jocelyn Yao  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Sam Frazier Sam Harley Ava Mirzadegan Molly Moore  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e1adf1e6b58d802259b198031ff02e36","permalink":"https://lmcl-umd.github.io./project/17_18_alum/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/17_18_alum/","section":"project","summary":" Sam Frazier Sam Harley Ava Mirzadegan Molly Moore  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Afiong Onyile David Silversmith Rafael Zuleta *  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"02bfbcd60a660c0da15703ce1f9cef62","permalink":"https://lmcl-umd.github.io./project/17_18_alum2/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/17_18_alum2/","section":"project","summary":" Afiong Onyile David Silversmith Rafael Zuleta *  ","tags":null,"title":"","type":"project"},{"authors":["Leon Li","L. Robert Slevc"],"categories":null,"content":"","date":1459468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459468800,"objectID":"674cf1c0fbb6691bdb85f426c3cbff5f","permalink":"https://lmcl-umd.github.io./publication/pub14/","publishdate":"2016-04-01T00:00:00Z","relpermalink":"/publication/pub14/","section":"publication","summary":"Every word signifies multiple senses. Many studies using comprehension‐based measures suggest that polysemes’ senses (e.g., paper as in printer paper or term paper) share lexical representations, whereas homophones’ meanings (e.g., pen as in ballpoint pen or pig pen) correspond to distinct lexical representations. Less is known about the lexical representations of polysemes compared to homophones in language production. In this study, speakers named pictures after reading sentence fragments that primed polysemes and homophones either as direct competitors to pictures (i.e., semantic‐competitors), or as indirect‐competitors to pictures (e.g., polysemous senses of semantic competitors, or homophonous meanings of semantic competitors). Polysemes (e.g., paper) elicited equal numbers of intrusions to picture names (e.g., cardboard) compared to in control conditions whether primed as direct competitors (printer paper) or as indirect‐competitors (term paper). This contrasted with the finding that homophones (e.g., pen) elicited more intrusions to picture names (e.g., crayon) compared to in control conditions when primed as direct competitors (ballpoint pen) than when primed as indirect‐competitors (pig pen). These results suggest that polysemes, unlike homophones, are stored and retrieved as unified lexical representations.","tags":["Language production","Lexical access","Meaning","Polysemy"],"title":"Of papers and pens: Polysemes and homophones in lexical (mis)selection","type":"publication"},{"authors":["L. Robert Slevc","Yasmeen Faroqi-Shah","Sadhvi Saxena","Brooke M. Okada"],"categories":null,"content":"","date":1459468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1459468800,"objectID":"62c85b7d8575b4ec49750ee7e3eef582","permalink":"https://lmcl-umd.github.io./publication/pub15/","publishdate":"2016-04-01T00:00:00Z","relpermalink":"/publication/pub15/","section":"publication","summary":"Evidence for shared processing of structure (or syntax) in language and in music conflicts with neuropsychological dissociations between the two. However, while harmonic structural processing can be impaired in patients with spared linguistic syntactic abilities (Peretz, I. (1993). Auditory atonalia for melodies. Cognitive Neuropsychology, 10, 21–56. doi:10.1080/02643299308253455), evidence for the opposite dissociation–preserved harmonic processing despite agrammatism–is largely lacking. Here, we report one such case: HV, a former musician with Broca’s aphasia and agrammatic speech, was impaired in making linguistic, but not musical, acceptability judgments. Similarly, she showed no sensitivity to linguistic structure, but normal sensitivity to musical structure, in implicit priming tasks. To our knowledge, this is the first non-anecdotal report of a patient with agrammatic aphasia demonstrating preserved harmonic processing abilities, supporting claims that aspects of musical and linguistic structure rely on distinct neural mechanisms.","tags":["Language","music","syntax","agrammatism","atonalia"],"title":"Preserved processing of musical structure in a person with agrammatic aphasia","type":"publication"},{"authors":["L. Robert Slevc","Nicholas S. Davey","Jared A. Linck"],"categories":null,"content":"","date":1454284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454284800,"objectID":"005bb56bc8f18a673bf57b9c5d09cbc8","permalink":"https://lmcl-umd.github.io./publication/pub19/","publishdate":"2016-02-01T00:00:00Z","relpermalink":"/publication/pub19/","section":"publication","summary":"Considerable work has used language-switching tasks to investigate how bilinguals manage competition between languages. Language-switching costs have been argued to reflect persisting inhibition or persisting activation of a non-target language. However, these costs might instead reflect the use of bivalent stimuli (i.e. pictures or digits that can be responded to in either language). That is, language-switching costs may simply reflect a cost of selecting the task-appropriate response for a given item and so may not be reflective of bilingual lexical access [Finkbeiner, M., Almeida, J., Janssen, N., \u0026 Carramaza, A. (2006). Lexical selection in bilingual speech production does not involve language suppression. Journal of Experimental Psychology: Learning, Memory, and Cognition, 32(5), 1075–1089]. The present study addresses this concern by having Chinese/English bilinguals switch between languages in response to inherently univalent stimuli (English words and Chinese Characters) as well as lexically univalent, but orthographically bivalent, stimuli (English words and Chinese Pinyin). Speakers showed switch costs when naming both univalent and orthographically bivalent stimuli, showing that switch costs can be found even with inherently univalent stimuli.","tags":["Language switching","bilingualism","language production"],"title":"A new look at 'the hard problem' of bilingual lexical access: Evidence for language switch costs with univalent stimuli","type":"publication"},{"authors":["Christopher C. Heffner","L. Robert Slevc"],"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"26eb9e93899450a98a456753d16fc209","permalink":"https://lmcl-umd.github.io./publication/pub20/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/publication/pub20/","section":"publication","summary":"What structural properties do language and music share? Although early speculation identified a wide variety of possibilities, the literature has largely focused on the parallels between musical structure and syntactic structure. Here, we argue that parallels between musical structure and prosodic structure deserve more attention. We review the evidence for a link between musical and prosodic structure and find it to be strong. In fact, certain elements of prosodic structure may provide a parsimonious comparison with musical structure without sacrificing empirical findings related to the parallels between language and music. We then develop several predictions related to such a hypothesis.","tags":["musical structure","prosody","prosodic structure","music perception","speech perception"],"title":"Prosodic structure as a parallel to musical structure","type":"publication"},{"authors":["Shota Momma","L. Robert Slevc","Colin Phillips"],"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"02007a8382d2128776401aa4fb38a369","permalink":"https://lmcl-umd.github.io./publication/pub17/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/publication/pub17/","section":"publication","summary":"Many influential models of sentence production (e.g., Bock \u0026 Levelt, 1994; Kempen \u0026 Hoenkamp, 1987; Levelt, 1989) emphasize the central role of verbs in structural encoding, and thus predict that verbs should be selected early in sentence formulation, possibly even before the phonological encoding of the first constituent (Ferreira, 2000). However, the most direct experimental test of this hypothesis (Schriefers, Teruel, \u0026 Meinshausen, 1998) found no evidence for advance verb selection in verb-final (subject-verb and subject-object-verb) utterances in German. The current study, based on a multiword picture-word interference task (Meyer, 1996; Schriefers et al., 1998), demonstrates that in Japanese, a strongly verb-final language, verbs are indeed planned in advance, but selectively before object noun articulation and not before subject noun articulation. This contrasting pattern of advance verb selection may reconcile the motivation for advance verb selection in structural encoding while explaining the previous failures to demonstrate it. Potential mechanisms that might underlie this contrasting pattern of advance verb selection are discussed.","tags":null,"title":"The timing of verb selection in Japanese sentence production","type":"publication"},{"authors":["Richard Kunert","L. Robert Slevc"],"categories":null,"content":"","date":1433116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433116800,"objectID":"88ea802a0eae9f73ede0aab4f76ed2a1","permalink":"https://lmcl-umd.github.io./publication/pub22/","publishdate":"2015-06-01T00:00:00Z","relpermalink":"/publication/pub22/","section":"publication","summary":"A commentary on Neural overlap in processing music and speech.","tags":null,"title":"A commentary on: 'Neural overlap in processing music and speech' (Peretz et al., 2015)","type":"publication"},{"authors":["L. Robert Slevc","Alison Shell"],"categories":null,"content":"","date":1433116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433116800,"objectID":"3edad7af0d12bfdb5cd5e817025e1ddb","permalink":"https://lmcl-umd.github.io./publication/pub24/","publishdate":"2015-06-01T00:00:00Z","relpermalink":"/publication/pub24/","section":"publication","summary":"Auditory agnosia refers to impairments in sound perception and identification despite intact hearing, cognitive functioning, and language abilities (reading, writing, and speaking). Auditory agnosia can be general, affecting all types of sound perception, or can be (relatively) specific to a particular domain. Verbal auditory agnosia (also known as (pure) word deafness) refers to deficits specific to speech processing, environmental sound agnosia refers to difficulties confined to non-speech environmental sounds, and amusia refers to deficits confined to music. These deficits can be apperceptive, affecting basic perceptual processes, or associative, affecting the relation of a perceived auditory object to its meaning. This chapter discusses what is known about the behavioral symptoms and lesion correlates of these different types of auditory agnosia (focusing especially on verbal auditory agnosia), evidence for the role of a rapid temporal processing deficit in some aspects of auditory agnosia, and the few attempts to treat the perceptual deficits associated with auditory agnosia. A clear picture of auditory agnosia has been slow to emerge, hampered by the considerable heterogeneity in behavioral deficits, associated brain damage, and variable assessments across cases. Despite this lack of clarity, these striking deficits in complex sound processing continue to inform our understanding of auditory perception and cognition.","tags":["amusia","auditory agnosia","environmental sound agnosia","pure word deafness","rapid temporal processing","speech perception deficits"],"title":"Auditory Agnosia","type":"publication"},{"authors":["L. Robert Slevc","Brooke M. Okada"],"categories":null,"content":"","date":1433116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433116800,"objectID":"d63e144e29bf4538bffde1fa4f57be19","permalink":"https://lmcl-umd.github.io./publication/pub23/","publishdate":"2015-06-01T00:00:00Z","relpermalink":"/publication/pub23/","section":"publication","summary":"The relationship between structural processing in music and language has received increasing interest in the past several years, spurred by the influential Shared Syntactic Integration Resource Hypothesis (SSIRH; Patel, Nature Neuroscience, 6, 674–681, 2003). According to this resource-sharing framework, music and language rely on separable syntactic representations but recruit shared cognitive resources to integrate these representations into evolving structures. The SSIRH is supported by findings of interactions between structural manipulations in music and language. However, other recent evidence suggests that such interactions also can arise with nonstructural manipulations, and some recent neuroimaging studies report largely nonoverlapping neural regions involved in processing musical and linguistic structure. These conflicting results raise the question of exactly what shared (and distinct) resources underlie musical and linguistic structural processing. This paper suggests that one shared resource is prefrontal cortical mechanisms of cognitive control, which are recruited to detect and resolve conflict that occurs when expectations are violated and interpretations must be revised. By this account, musical processing involves not just the incremental processing and integration of musical elements as they occur, but also the incremental generation of musical predictions and expectations, which must sometimes be overridden and revised in light of evolving musical input.","tags":["Language","Music","Syntax","Cognitive control","Musical ambiguity"],"title":"Processing structure in language and music: a case for shared reliance on cognitive control","type":"publication"},{"authors":["Alison Shell","Jared Linck","L. Robert Slevc"],"categories":null,"content":"","date":1430438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430438400,"objectID":"29f6413e36ae417d04744cc02f0c8a43","permalink":"https://lmcl-umd.github.io./publication/pub21/","publishdate":"2015-05-01T00:00:00Z","relpermalink":"/publication/pub21/","section":"publication","summary":"Bilingual language production is widely believed to be a competitive process. Bilinguals may manage this competition by relying on inhibiting one language while speaking in the other. However, it remains unclear if this process relies on domain general inhibitory mechanisms, and, if so, when and where during language production inhibitory control is applied. The current study investigates these issues by experimentally manipulating demand on inhibitory control using a picture word interference task during a language switching paradigm. Switching costs were not exacerbated when inhibitory control was taxed; in fact language switching was less costly during inhibition-demanding trials. These findings do not support the idea that inhibitory control mechanisms underlie language switching and suggest that language switching and the resolution of within-language lexical competition do not share inhibitory resources.","tags":null,"title":"Examining the role of inhibitory control in bilingual language switching","type":"publication"},{"authors":["Randi C. Martin","L. Robert Slevc"],"categories":null,"content":"","date":1396310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396310400,"objectID":"eec95cd59fecee85271886346ee8c69a","permalink":"https://lmcl-umd.github.io./publication/pub26/","publishdate":"2014-04-01T00:00:00Z","relpermalink":"/publication/pub26/","section":"publication","summary":"The role of working memory in language production is considered at different levels of planning. At the message level, there is mixed evidence regarding a role for short-term memory or working memory in discourse fluency and coherence and stronger evidence for a role in the production of referring expressions. A somewhat larger body of evidence exists with respect to the level of grammatical encoding, with studies on accessibility and agreement implicating effects of retrieval interference in working memory. Regarding scope of planning, evidence drawn primarily from brain-damaged patients suggests a role for memory capacity at the lexical-semantic level rather than phonological level in phrasal planning. In contrast, some findings from neurally intact individuals implicate multiword planning at the phonological level, perhaps implicating a phonological output buffer. Future work is needed to integrate findings from production planning with different approaches to working memory.","tags":["working memory","short-term memory","scope of planning","retrieval interference"],"title":"Language production and working memory","type":"publication"},{"authors":["Thomas A. Carlson","Ryan A. Simmons","Nikolaus Kriegeskorte","L. Robert Slevc"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"9d62fa848634af707e446599e87ee3c7","permalink":"https://lmcl-umd.github.io./publication/pub25/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/pub25/","section":"publication","summary":"In the ventral visual pathway, early visual areas encode light patterns on the retina in terms of image properties, for example, edges and color, whereas higher areas encode visual information in terms of objects and categories. At what point does semantic knowledge, as instantiated in human language, emerge? We examined this question by studying whether semantic similarity in language relates to the brain's organization of object representations in inferior temporal cortex (ITC), an area of the brain at the crux of several proposals describing how the brain might represent conceptual knowledge. Semantic relationships among words can be viewed as a geometrical structure with some pairs of words close in their meaning (e.g., man and boy) and other pairs more distant (e.g., man and tomato). ITC's representation of objects similarly can be viewed as a complex structure with some pairs of stimuli evoking similar patterns of activation (e.g., man and boy) and other pairs evoking very different patterns (e.g., man and tomato). In this study, we examined whether the geometry of visual object representations in ITC bears a correspondence to the geometry of semantic relationships between word labels used to describe the objects. We compared ITC's representation to semantic structure, evaluated by explicit ratings of semantic similarity and by five computational measures of semantic similarity. We show that the representational geometry of ITC—but not of earlier visual areas (V1)—is reflected both in explicit behavioral ratings of semantic similarity and also in measures of semantic similarity derived from word usage patterns in natural language. Our findings show that patterns of brain activity in ITC not only reflect the organization of visual information into objects but also represent objects in a format compatible with conceptual thought and language.","tags":null,"title":"The emergence of semantic meaning in the ventral temporal pathway","type":"publication"},{"authors":["L. Robert Slevc","Jared M. Novick"],"categories":null,"content":"","date":1375315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375315200,"objectID":"90009f4cdd0bb3990dc3be3cf68c44bd","permalink":"https://lmcl-umd.github.io./publication/pub28/","publishdate":"2013-08-01T00:00:00Z","relpermalink":"/publication/pub28/","section":"publication","summary":"Pickering \u0026 Garrod's (P\u0026G's) integrated model of production and comprehension includes no explicit role for nonlinguistic cognitive processes. Yet, how domain-general cognitive functions contribute to language processing has become clearer with well-specified theories and supporting data. We therefore believe that their account can benefit by incorporating functions like working memory and cognitive control into a unified model of language processing.","tags":null,"title":"Memory and cognitive control in an integrated theory of language processing","type":"publication"},{"authors":["L. Robert Slevc","Jason G. Reitman","Brooke M. Okada"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"660ec684fa3bd8514289dd579598cac3","permalink":"https://lmcl-umd.github.io./publication/pub29/","publishdate":"2013-01-01T00:00:00Z","relpermalink":"/publication/pub29/","section":"publication","summary":"The relationship between structural (or syntactic) processing in music and in language is not yet clear. Evidence indicating that these two processes are shared conflicts with other results suggesting that they are largely distinct. These conflicting findings suggest that musical and linguistic processing may share some, but not all, underlying processes, raising the question of what exactly those shared processes might be. Two experiments tested the idea that one shared process is cognitive control by pairing manipulations of musical structure with the Stroop task, a standard test of cognitive control. Manipulations of harmonic expectancy, but not of timbral expectancy, interacted with Stroop interference effects, suggesting that cognitive control is at least one specific process underlying shared syntactic processing in music and language.","tags":["cognitive control","music and language","musical syntax"],"title":"Syntax in music and language: The role of cognitive control ","type":"publication"},{"authors":["L. Robert Slevc","Victor S. Ferreira"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"5f0fa2645a2760f59c68b11eccbb8c88","permalink":"https://lmcl-umd.github.io./publication/pub27/","publishdate":"2013-01-01T00:00:00Z","relpermalink":"/publication/pub27/","section":"publication","summary":"Natural language contains disfluencies and errors. Do listeners simply discard information that was clearly produced in error, or can erroneous material persist to affect subsequent processing? Two experiments explored this question using a structural priming paradigm. Speakers described dative- eliciting pictures after hearing prime sentences that either were disfluent but with a consistent dative structure or were sentences that began as datives but were corrected to transitives (e.g., The mechanic is giving the new part . . . uh . . . is recognizing the new part). If an erroneous and corrected sentence fragment is discarded, then the original form of an ultimately transitive utterance should not influence future production. However, if the syntactic parse of an error is not discarded, then it should influence speakers’ subsequent choice of syntactic structure. In both experiments, structural priming was signifi- cantly reduced when primes were corrected to a non-dative structure (relative to disfluent but ultimately dative primes). However, target descriptions did show an influence from corrected errors when the prime and target shared the same verb. Thus, a parse mapping a verb to a specific argument structure can persist despite being explicitly marked as an error, reflecting the incremental and predictive nature of compre- hension.","tags":["syntactic priming","parsing","errors","repairs"],"title":"To err is human; to structurally prime from errors is also human","type":"publication"},{"authors":["Anthony Brandt","Molly Gebrian","L. Robert Slevc"],"categories":null,"content":"","date":1351728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1351728000,"objectID":"2c7c8db5ee575840adfef3f7923dda2a","permalink":"https://lmcl-umd.github.io./publication/pub30/","publishdate":"2012-11-01T00:00:00Z","relpermalink":"/publication/pub30/","section":"publication","summary":"Language is typically viewed as fundamental to human intelligence. Music, while recognized as a human universal, is often treated as an ancillary ability – one dependent on or derivative of language. In contrast, we argue that it is more productive from a developmental perspective to describe spoken language as a special type of music. A review of existing studies presents a compelling case that musical hearing and ability is essential to language acquisition. In addition, we challenge the prevailing view that music cognition matures more slowly than language and is more difficult; instead, we argue that music learning matches the speed and effort of language acquisition. We conclude that music merits a central place in our understanding of human development.","tags":["music","language","language acquisition","childhood development","musical development","music cognition","definition of music","emergent modularity"],"title":"Music and early language acquisition","type":"publication"},{"authors":["L. Robert Slevc"],"categories":null,"content":"","date":1343779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1343779200,"objectID":"245d289e89e538c6a49ede263dff8c62","permalink":"https://lmcl-umd.github.io./publication/pub31/","publishdate":"2012-08-01T00:00:00Z","relpermalink":"/publication/pub31/","section":"publication","summary":"Language and music are the most impressive examples of humans’ capacity to process complex sound and structure. Though interest in the relationship between these two abilities has a long history, only recently has cognitive and neuroscientific research started to illuminate both what is shared and what is distinct between linguistic and musical processing. This review considers evidence for a link between language and music at three levels of analysis: sound, structure, and meaning. These links not only inform our understanding of language and music, but also add to a more basic understanding of our processing of complex auditory stimuli, structure, meaning, and emotion.","tags":null,"title":"Language and music: sound, structure, and meaning","type":"publication"},{"authors":["Randi C Martin","L. Robert Slevc"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"a6f20ca89b93fb04c87914dbbea62ee6","permalink":"https://lmcl-umd.github.io./publication/pub32/","publishdate":"2012-01-01T00:00:00Z","relpermalink":"/publication/pub32/","section":"publication","summary":"","tags":null,"title":"Memory disorders and impaired language and communication","type":"publication"},{"authors":["L. Robert Slevc"],"categories":null,"content":"","date":1320105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1320105600,"objectID":"ecc59c56bcd3c8dc4dd0fe6106a76d69","permalink":"https://lmcl-umd.github.io./publication/pub33/","publishdate":"2011-11-01T00:00:00Z","relpermalink":"/publication/pub33/","section":"publication","summary":"The role of working memory (WM) in sentence comprehension has received considerable interest, but little work has investigated how sentence production relies on memory mechanisms. Three experiments investigated speakers’ tendency to produce syntactic structures that allow for early production of material that is accessible in memory. In Experiment 1, speakers produced accessible information early less often when under a verbal WM load than when under no load. Experiment 2 found the same pattern for given-new ordering (i.e., when accessibility was manipulated by making information given). Experiment 3 addressed the possibility that these effects do not reflect WM mechanisms but rather increased task difficulty by relying on the distinction between verbal and spatial WM: Speakers’ tendency to produce sentences respecting given-new ordering was reduced more by a verbal than by a spatial WM load. These patterns show that accessibility effects do in fact reflect accessibility in verbal WM and that representations in sentence production are vulnerable to interference from other information in memory.","tags":["language production","grammatical encoding","working memory","accessibility effects","similarity-based interference"],"title":"Saying what's on your mind: Working memory effects on sentence production","type":"publication"},{"authors":["L. Robert Slevc","Aniruddh D.Patel"],"categories":null,"content":"","date":1306886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1306886400,"objectID":"040e0efd9a61c7c970ce2207f92d16fc","permalink":"https://lmcl-umd.github.io./publication/pub35/","publishdate":"2011-06-01T00:00:00Z","relpermalink":"/publication/pub35/","section":"publication","summary":"","tags":["Review"],"title":"Meaning in music and language: Three key differences. Comment on “Towards a neural basis of processing musical semantics” by Stefan Koelsch","type":"publication"},{"authors":["L. Robert Slevc","Randi C.Martin","A. Cris Hamilton","Marc F. Joanisse"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"880c474a3cfa58611ac89c99791941b9","permalink":"https://lmcl-umd.github.io./publication/pub34/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/publication/pub34/","section":"publication","summary":"The mechanisms and functional anatomy underlying the early stages of speech perception are still not well understood. One way to investigate the cognitive and neural underpinnings of speech perception is by investigating patients with speech perception deficits but with preserved ability in other domains of language. One such case is reported here: patient NL shows highly impaired speech perception despite normal hearing ability and preserved semantic knowledge, speaking, and reading ability, and is thus classified as a case of pure word deafness (PWD). NL has a left temporoparietal lesion without right hemisphere damage and DTI imaging suggests that he has preserved cross-hemispheric connectivity, arguing against an account of PWD as a disconnection of left lateralized language areas from auditory input. Two experiments investigated whether NL's speech perception deficit could instead result from an underlying problem with rapid temporal processing. Experiment 1 showed that NL has particular difficulty discriminating sounds that differ in terms of rapid temporal changes, be they speech or non-speech sounds. Experiment 2 employed an intensive training program designed to improve rapid temporal processing in language impaired children (Fast ForWord; Scientific Learning Corporation, Oakland, CA) and found that NL was able to improve his ability to discriminate rapid temporal differences in non-speech sounds, but not in speech sounds. Overall, these data suggest that patients with unilateral PWD may, in fact, have a deficit in (left lateralized) temporal processing ability, however they also show that a rapid temporal processing deficit is, by itself, unable to account for this patient's speech perception deficit.","tags":["Speech perception","Rapid temporal processing","Pure word deafness","Lateralization"],"title":"Speech perception, rapid temporal processing, and the left hemisphere: A case study of unilateral pure word deafness","type":"publication"},{"authors":["L. Robert Slevc","Jason C. Rosenberg","Aniruddh D.Patel"],"categories":null,"content":"","date":1238544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1238544000,"objectID":"a4944c25866c5f68808c0e7a8a0dbe31","permalink":"https://lmcl-umd.github.io./publication/pub36/","publishdate":"2009-04-01T00:00:00Z","relpermalink":"/publication/pub36/","section":"publication","summary":"Linguistic processing, especially syntactic processing, is often considered a hallmark of human cognition; thus, the domain specificity or domain generality of syntactic processing has attracted considerable debate. The present experiments address this issue by simultaneously manipulating syntactic processing demands in language and music. Participants performed self-paced reading of garden path sentences, in which structurally unexpected words cause temporary syntactic processing difficulty. A musical chord accompanied each sentence segment, with the resulting sequence forming a coherent chord progression. When structurally unexpected words were paired with harmonically unexpected chords, participants showed substantially enhanced garden path effects. No such interaction was observed when the critical words violated semantic expectancy or when the critical chords violated timbral expectancy. These results support a prediction of the shared syntactic integration resource hypothesis (Patel, 2003), which suggests that music and language draw on a common pool of limited processing resources for integrating incoming elements into syntactic structures. Notations of the stimuli from this study may be downloaded from pbr.psychonomic-journals.org/content/supplemental.","tags":["Critical Word","Musical Training","Syntactic Processing","Garden Path","Pitch Class"],"title":"Making psycholinguistics musical: Self-paced reading time evidence for shared processing of linguistic and musical syntax ","type":"publication"},{"authors":["Liane Wardlow Lane","L. Robert Slevc","Victor S. Ferreira"],"categories":null,"content":"","date":1175385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1175385600,"objectID":"49e7d5ab82504d5b601c61ce12d38597","permalink":"https://lmcl-umd.github.io./publication/pub39/","publishdate":"2007-04-01T00:00:00Z","relpermalink":"/publication/pub39/","section":"publication","summary":"","tags":null,"title":"Exchanging elicits: Stem-exchange errors and syntactic category shifts","type":"publication"},{"authors":["L. Robert Slevc","Victor S. Ferreira"],"categories":null,"content":"","date":1175385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1175385600,"objectID":"d178b5c0e5611bf2312bcc46533682b1","permalink":"https://lmcl-umd.github.io./publication/pub37/","publishdate":"2007-04-01T00:00:00Z","relpermalink":"/publication/pub37/","section":"publication","summary":"","tags":null,"title":"Grammatical encoding","type":"publication"},{"authors":["L. Robert Slevc","Liane Wardlow Lane","Victor S. Ferreira"],"categories":null,"content":"","date":1175385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1175385600,"objectID":"c834a18e215e8a242b4703be04c2da8b","permalink":"https://lmcl-umd.github.io./publication/pub38/","publishdate":"2007-04-01T00:00:00Z","relpermalink":"/publication/pub38/","section":"publication","summary":"Number agreement and grammatical gender agreement are susceptible to attraction, where characteristics of other sentence elements lead to agreement errors. Previous evidence and theories suggest that attraction happens as a syntactic or lexical process (i.e., involving word-knowledge), rather than as a conceptual process (i.e., involving world-knowledge). The current paper presents data on a different type of agreement: agreement in notional/conceptual gender between genitive pronouns and their antecedents. We find that conceptual gender agreement is also susceptible to attraction, but unlike number or grammatical gender agreement, this attraction happens as a conceptual process, not a syntactic/lexical process.","tags":null,"title":"Pronoun production: Word or world knowledge?","type":"publication"},{"authors":["L. Robert Slevc","Akira Miyake"],"categories":null,"content":"","date":1154390400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1154390400,"objectID":"d5f6bd4e60be35991dd65ebf513bb02a","permalink":"https://lmcl-umd.github.io./publication/pub40/","publishdate":"2006-08-01T00:00:00Z","relpermalink":"/publication/pub40/","section":"publication","summary":"This study examined the relation between musical ability and second-language (L2) proficiency in adult learners. L2 ability was assessed in four domains: receptive phonology, productive phonology, syntax, and lexical knowledge. Also assessed were various other factors that might explain individual differences in L2 ability, including age of L2 immersion, patterns of language use and exposure, and phonological short-term memory. Hierarchical regression analyses were conducted to determine if musical ability explained any unique variance in each domain of L2 ability after controlling for other relevant factors. Musical ability predicted L2 phonological ability (both receptive and productive) even when controlling for other factors, but did not explain unique variance in L2 syntax or lexical knowledge. These results suggest that musical skills may facilitate the acquisition of L2 sound structure and add to a growing body of evidence linking language and music.","tags":null,"title":"Individual differences in second-language proficiency: Does musical ability matter?","type":"publication"},{"authors":["Joseph P. McCleery","Lisa Tully","L. Robert Slevc","Laura Schreibman"],"categories":null,"content":"","date":1146441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1146441600,"objectID":"b937e93f8fae0b0824c1b290052260da","permalink":"https://lmcl-umd.github.io./publication/pub42/","publishdate":"2006-05-01T00:00:00Z","relpermalink":"/publication/pub42/","section":"publication","summary":"While much attention has been given to documenting the language skills of verbal children with autism, the basic speech sound development patterns of severely language-impaired children with autism are unknown. Previous research has shown that certain consonants are generally produced earlier in development than other consonants, both in typically developing children and in children with language-learning impairments. While several large studies indicate that children with autism who have strong verbal skills have intact phonological development, there is some evidence that children with autism who are more severely language impaired may have abnormal phonological production. This study documents the speech sound development of non-verbal and minimally verbal children with autism. Prompts were administered for each individual speech sound while spontaneous and imitated sounds were recorded and scored. Results indicate that children with autism show the same general speech sound production patterns as typically developing and language-learning impaired children.","tags":null,"title":"Consonant production patterns of young severely language-delayed children with autism","type":"publication"},{"authors":["L. Robert Slevc","Victor S. Ferreira"],"categories":null,"content":"","date":1136073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136073600,"objectID":"3b4c66bb21f154e43dd30e3f03e28181","permalink":"https://lmcl-umd.github.io./publication/pub41/","publishdate":"2006-01-01T00:00:00Z","relpermalink":"/publication/pub41/","section":"publication","summary":"The perceptual loop theory of speech monitoring (Levelt, 1983) claims that inner and overt speech are monitored by the comprehension system, which detects errors by comparing the comprehension of formulated utterances to originally intended utterances. To test the perceptual loop monitor, speakers named pictures and sometimes attempted to halt speech in response to auditory (Experiments 1 and 3) or visual (Experiments 2, 4, and 5) words that differed from the picture name. These stop-signal words were varied in terms of their semantic or phonological similarity to the intended word. The ability to halt word production was sensitive to phonological similarity and, in Experiment 5, to emotional valence, but not to semantic similarity. These results suggest that the perceptual loop detects errors by making comparisons at a level where phonological knowledge is represented. These data also imply that dialogue, back channeling, and other areas where speech production is affected by simultaneous comprehension may operate based on phonological comparisons.","tags":["Self monitoring","Perceptual loop theory","Speech errors"],"title":"Halting in single word production: A test of the perceptual loop theory of speech monitoring","type":"publication"},{"authors":["Victor S.Ferreira","L. Robert Slevc","Erin S. Rogers"],"categories":null,"content":"","date":1120176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1120176000,"objectID":"60d0d35049e21796cd87845a2a71d74b","permalink":"https://lmcl-umd.github.io./publication/pub43/","publishdate":"2005-07-01T00:00:00Z","relpermalink":"/publication/pub43/","section":"publication","summary":"Three experiments assessed how speakers avoid linguistically and nonlinguistically ambiguous expressions. Speakers described target objects (a flying mammal, bat) in contexts including foil objects that caused linguistic (a baseball bat) and nonlinguistic (a larger flying mammal) ambiguity. Speakers sometimes avoided linguistic-ambiguity, and they did so equally regardless of whether they also were about to describe foils. This suggests that comprehension processes can sometimes detect linguistic-ambiguity before producing it. However, once produced, speakers consistently avoided using the same linguistically ambiguous expression again for a different meaning. This suggests that production processes can successfully detect linguistic-ambiguity after-the-fact. Speakers almost always avoided nonlinguistic-ambiguity. Thus, production processes are especially sensitive to nonlinguistic- but not linguistic-ambiguity, with the latter avoided consistently only once it is already articulated.","tags":["Language production","Referential communication","Ambiguity","Monitoring","Homophones"],"title":"How do speakers avoid ambiguous linguistic expressions?","type":"publication"},{"authors":null,"categories":null,"content":" Nick Davey * Bako Ekoko Ilana Green Kyeougeun Kim  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b1fa178567662a7b9077880aab2ee461","permalink":"https://lmcl-umd.github.io./project/11_14_alum/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/11_14_alum/","section":"project","summary":" Nick Davey * Bako Ekoko Ilana Green Kyeougeun Kim  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Teresa Longo Annahid Meyssami Rukayat Muse-Ariyoh Ilanna Newman  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"eba000d656879b54bc2d7ab48348216d","permalink":"https://lmcl-umd.github.io./project/11_14_alum2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/11_14_alum2/","section":"project","summary":" Teresa Longo Annahid Meyssami Rukayat Muse-Ariyoh Ilanna Newman  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Daniel Paul Anjana Rao Joshua Robusto Sadhvi Saxena  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b73ed37bebdf92abdd4e39372d5cd410","permalink":"https://lmcl-umd.github.io./project/11_14_alum3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/11_14_alum3/","section":"project","summary":" Daniel Paul Anjana Rao Joshua Robusto Sadhvi Saxena  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Brad Schachat Ryan Simmons Eliana Sudikoff  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8e44eb725e77e4ec80c55ea378fa5633","permalink":"https://lmcl-umd.github.io./project/11_14_alum4/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/11_14_alum4/","section":"project","summary":" Brad Schachat Ryan Simmons Eliana Sudikoff  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Zarsh Bhatti Nick Brown Brittni Bittner Jeff Chang  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"669da1d3c1d31088838450424a43af1b","permalink":"https://lmcl-umd.github.io./project/14_15_alum/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/14_15_alum/","section":"project","summary":" Zarsh Bhatti Nick Brown Brittni Bittner Jeff Chang  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Chris Eyo Dan Lerner Leon Li * Danielle Dubois  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f8fed185a5f3a705d0bf4cf193e1e2fa","permalink":"https://lmcl-umd.github.io./project/14_15_alum2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/14_15_alum2/","section":"project","summary":" Chris Eyo Dan Lerner Leon Li * Danielle Dubois  ","tags":null,"title":"","type":"project"},{"authors":null,"categories":null,"content":" Lisa Kaufman Quyen Kieu Omar Mejia Nabil Morad  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9de1bcac206656d369188d26206c181c","permalink":"https://lmcl-umd.github.io./project/14_15_alum3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/14_15_alum3/","section":"project","summary":" Lisa Kaufman Quyen Kieu Omar Mejia Nabil Morad  ","tags":null,"title":"","type":"project"}]